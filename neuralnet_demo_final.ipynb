{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data \n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dotua.rautodiff import rAutoDiff as rad\n",
    "from Dotua.roperator import rOperator as op\n",
    "import random\n",
    "\n",
    "rad = rad()\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, input_vals, input_bias, hidden_bias, num_hidden, output, learning_rate = 0.1):\n",
    "        self.input_vals = input_vals\n",
    "        self.input_bias = input_bias\n",
    "        self.hidden_bias = hidden_bias\n",
    "        self.num_hidden = num_hidden\n",
    "        self.output = output\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.weights_tohidden = [None] * num_hidden\n",
    "        for i in range(num_hidden):\n",
    "            self.weights_tohidden[i] = []\n",
    "            for j in range(len(input_vals)):\n",
    "                \n",
    "                #DOTUA USED HERE: to initalize the weights from the input to hidden layer.\n",
    "                w = rad.create_rscalar(random.random())\n",
    "                self.weights_tohidden[i].append(w)\n",
    "                self.weights_tooutput = [None] * len(output)\n",
    "        \n",
    "        for i in range(len(output)):\n",
    "            self.weights_tooutput[i] = []\n",
    "            \n",
    "            #DOTUA USED HERE: to initialize weights from hidden to output.\n",
    "            w = rad.create_rscalar(random.random())\n",
    "            for j in range(num_hidden):\n",
    "                self.weights_tooutput[i].append(w)\n",
    "\n",
    "    def train(self, input_vals, output_vals):\n",
    "        self.input_vals = input_vals\n",
    "        self.output = output_vals\n",
    "\n",
    "        #calculation of hidden layer.\n",
    "        self.hidden_layer = []\n",
    "        for i in range(self.num_hidden):\n",
    "            h = 0\n",
    "            for j in range(len(self.weights_tohidden[i])):\n",
    "                h = h + self.weights_tohidden[i][j] * self.input_vals[j]\n",
    "            h = h + self.input_bias\n",
    "            self.hidden_layer.append(1/(1+op.exp(-h)))\n",
    "\n",
    "        # To calculate the output layer neurons and error\n",
    "        error = 0\n",
    "        for i in range(len(self.output)):\n",
    "            o = 0\n",
    "            for j in range(len(self.weights_tooutput[i])):\n",
    "                o = o + self.weights_tooutput[i][j] * self.hidden_layer[j]\n",
    "            o = o + self.hidden_bias\n",
    "            o = 1/(1+op.exp(-o))\n",
    "            error = error + (o - self.output[i]) ** 2\n",
    "\n",
    "        # To update weights from hidden layer to output layer\n",
    "        for i in range(len(self.weights_tooutput)):\n",
    "            for j in range(len(self.weights_tooutput[i])):\n",
    "                \n",
    "                #DOTUA USED HERE:\n",
    "                d = rad.partial(error, self.weights_tooutput[i][j])\n",
    "                self.weights_tooutput[i][j] = self.weights_tooutput[i][j] - d * self.learning_rate\n",
    "\n",
    "        # To update weights from input layer to hidden layer\n",
    "        for i in range(len(self.weights_tohidden)):\n",
    "            for j in range(len(self.weights_tooutput[i])):\n",
    "                \n",
    "                #DOTUA USED HERE:\n",
    "                d = rad.partial(error, self.weights_tohidden[i][j])\n",
    "                self.weights_tohidden[i][j] = self.weights_tohidden[i][j] - d * self.learning_rate\n",
    "\n",
    "    def predict(self, input_vals, output_vals):\n",
    "        self.input_vals = input_vals\n",
    "        self.output = output_vals\n",
    "\n",
    "        # To calculate the hidden layer neurons using the current model\n",
    "        self.hidden_layer = []\n",
    "        for i in range(self.num_hidden):\n",
    "            h = 0\n",
    "            for j in range(len(self.weights_tohidden[i])):\n",
    "                h = h + self.weights_tohidden[i][j] * self.input_vals[j]\n",
    "            h = h + self.input_bias\n",
    "            self.hidden_layer.append(1/(1+op.exp(-h)))\n",
    "\n",
    "        # To calculate the output layer neurons using the current model and calculate the error \n",
    "        error = 0\n",
    "        output_layer = []\n",
    "        for i in range(len(self.output)):\n",
    "            o = 0\n",
    "            for j in range(len(self.weights_tooutput[i])):\n",
    "                o = o + self.weights_tooutput[i][j] * self.hidden_layer[j]\n",
    "            o = o + self.hidden_bias\n",
    "            o = 1/(1+op.exp(-o))\n",
    "            output_layer.append(o.val)\n",
    "            error = error + (o - self.output[i]) ** 2\n",
    "        error = error / len(self.output)\n",
    "        return (output_layer, error.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_y(i):\n",
    "    train_y = [0,0,0]\n",
    "    train_y[i] = 1\n",
    "    return train_y\n",
    "\n",
    "nn = NeuralNetwork([0,0,1],0.33,0.33,2,[0,0,1])\n",
    "\n",
    "for j in range(1000):\n",
    "    for i in range(1, len(X_train)):\n",
    "        nn.train(X_train[i], get_y(y_train[i]))\n",
    "\n",
    "train_e = []\n",
    "true_y = []\n",
    "predicted_y = []\n",
    "for i in range(1, len(X_train)):\n",
    "    output,e = nn.predict(X_train[i], get_y(y_train[i]))\n",
    "    train_e.append(e)\n",
    "\n",
    "    if max(output) == output[0]:\n",
    "        predicted_y.append(0)\n",
    "    elif max(output) == output[1]:\n",
    "        predicted_y.append(1)\n",
    "    else:\n",
    "        predicted_y.append(2)\n",
    "    \n",
    "    true_y.append(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(running_mean(train_e, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(true_y,predicted_y))\n",
    "print(confusion_matrix(true_y,predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(true_y,predicted_y),\n",
    "                     index=['setosa','versicolor','virginica'], columns=['setosa','versicolor','virginica'])\n",
    "plt.figure(figsize=(12,12))\n",
    "heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, fontsize=14)\n",
    "heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, fontsize=14)\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
