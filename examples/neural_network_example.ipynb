{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,2:]  #:2 we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6))\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1,\n",
    "            edgecolor='k')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2138)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Dotua.rautodiff import rAutoDiff as rad\n",
    "from Dotua.roperator import rOperator as op\n",
    "import random\n",
    "\n",
    "ad = rad()\n",
    "\n",
    "class NeuralNetwork():\n",
    "\tdef __init__(self, input_vals, input_bias, hidden_bias, num_hidden, output, learning_rate = 0.1):\n",
    "\t\tself.input_vals = input_vals\n",
    "\t\tself.input_bias = input_bias\n",
    "\t\tself.hidden_bias = hidden_bias\n",
    "\t\tself.num_hidden = num_hidden\n",
    "\t\tself.output = output\n",
    "\t\tself.learning_rate = learning_rate\n",
    "\n",
    "\t\t# To initialize the weights from input layer to hidden layer\n",
    "\t\tself.weights_tohidden = [None] * num_hidden\n",
    "\t\tfor i in range(num_hidden):\n",
    "\t\t\tself.weights_tohidden[i] = []\n",
    "\t\t\tfor j in range(len(input_vals)):\n",
    "\t\t\t\tw = ad.create_rscalar(random.random())\n",
    "\t\t\t\tself.weights_tohidden[i].append(w)\n",
    "\n",
    "\t\t# To initialize the weights from hidden layer to output layer\n",
    "\t\tself.weights_tooutput = [None] * len(output)\n",
    "\t\tfor i in range(len(output)):\n",
    "\t\t\tself.weights_tooutput[i] = []\n",
    "\t\t\tw = ad.create_rscalar(random.random())\n",
    "\t\t\tfor j in range(num_hidden):\n",
    "\t\t\t\tself.weights_tooutput[i].append(w)\n",
    "\n",
    "\tdef train(self, input_vals, output_vals):\n",
    "\t\tself.input_vals = input_vals\n",
    "\t\tself.output = output_vals\n",
    "\n",
    "\t\t# To calculate the hidden layer neurons\n",
    "\t\tself.hidden_layer = []\n",
    "\t\tfor i in range(self.num_hidden):\n",
    "\t\t\th = 0\n",
    "\t\t\tfor j in range(len(self.weights_tohidden[i])):\n",
    "\t\t\t\th = h + self.weights_tohidden[i][j] * self.input_vals[j]\n",
    "\t\t\th = h + self.input_bias\n",
    "\t\t\tself.hidden_layer.append(1/(1+op.exp(-h)))\n",
    "\n",
    "\t\t# To calculate the output layer neurons and error\n",
    "\t\terror = 0\n",
    "\t\tfor i in range(len(self.output)):\n",
    "\t\t\to = 0\n",
    "\t\t\tfor j in range(len(self.weights_tooutput[i])):\n",
    "\t\t\t\to = o + self.weights_tooutput[i][j] * self.hidden_layer[j]\n",
    "\t\t\to = o + self.hidden_bias\n",
    "\t\t\to = 1/(1+op.exp(-o))\n",
    "\t\t\terror = error + (o - self.output[i]) ** 2\n",
    "\n",
    "\t\t# To update weights from hidden layer to output layer\n",
    "\t\tfor i in range(len(self.weights_tooutput)):\n",
    "\t\t\tfor j in range(len(self.weights_tooutput[i])):\n",
    "\t\t\t\td = ad.partial(error, self.weights_tooutput[i][j])\n",
    "\t\t\t\tself.weights_tooutput[i][j] = self.weights_tooutput[i][j] - d * self.learning_rate\n",
    "\n",
    "\t\t# To update weights from input layer to hidden layer\n",
    "\t\tfor i in range(len(self.weights_tohidden)):\n",
    "\t\t\tfor j in range(len(self.weights_tooutput[i])):\n",
    "\t\t\t\td = ad.partial(error, self.weights_tohidden[i][j])\n",
    "\t\t\t\tself.weights_tohidden[i][j] = self.weights_tohidden[i][j] - d * self.learning_rate\n",
    "\n",
    "\tdef predict(self, input_vals, output_vals):\n",
    "\t\tself.input_vals = input_vals\n",
    "\t\tself.output = output_vals\n",
    "\n",
    "\t\t# To calculate the hidden layer neurons using the current model\n",
    "\t\tself.hidden_layer = []\n",
    "\t\tfor i in range(self.num_hidden):\n",
    "\t\t\th = 0\n",
    "\t\t\tfor j in range(len(self.weights_tohidden[i])):\n",
    "\t\t\t\th = h + self.weights_tohidden[i][j] * self.input_vals[j]\n",
    "\t\t\th = h + self.input_bias\n",
    "\t\t\tself.hidden_layer.append(1/(1+op.exp(-h)))\n",
    "\n",
    "\t\t# To calculate the output layer neurons using the current model and calculate the error\n",
    "\t\terror = 0\n",
    "\t\toutput_layer = []\n",
    "\t\tfor i in range(len(self.output)):\n",
    "\t\t\to = 0\n",
    "\t\t\tfor j in range(len(self.weights_tooutput[i])):\n",
    "\t\t\t\to = o + self.weights_tooutput[i][j] * self.hidden_layer[j]\n",
    "\t\t\to = o + self.hidden_bias\n",
    "\t\t\to = 1/(1+op.exp(-o))\n",
    "\t\t\toutput_layer.append(o.val)\n",
    "\t\t\terror = error + (o - self.output[i]) ** 2\n",
    "\t\terror = error / len(self.output)\n",
    "\t\treturn (output_layer, error.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction given by the Neural Network is  [0.36576268400301354, 0.35000176859821175]\n",
      "The mean squared error is  0.09708400350161306\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork([0.05,0.1],0.35,0.6,2,[0.01,0.09])\n",
    "for i in range(100):\n",
    "\tnn.train([0.05,0.1],[0.01,0.09])\n",
    "output, e = nn.predict([0.05,0.1],[0.01,0.09])\n",
    "print('Final prediction given by the Neural Network is ', output)\n",
    "print('The mean squared error is ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction given by the Neural Network is  [0.3355135962300062, 0.31790696161716203, 0.34875646122104836]\n",
      "The mean squared error is  0.2331504518363173\n",
      "Final prediction given by the Neural Network is  [0.33237288245745084, 0.3172624658169574, 0.3495010260506076]\n",
      "The mean squared error is  0.23291774692861442\n",
      "Final prediction given by the Neural Network is  [0.3454659609627771, 0.3201732068326598, 0.3467701024583335]\n",
      "The mean squared error is  0.2339202342836959\n",
      "Final prediction given by the Neural Network is  [0.4136130230361116, 0.35029127503814894, 0.3549618248654667]\n",
      "The mean squared error is  0.1975171870775074\n",
      "Final prediction given by the Neural Network is  [0.3171780149707294, 0.3138961025793877, 0.3528503959110166]\n",
      "The mean squared error is  0.20597842215594328\n",
      "Final prediction given by the Neural Network is  [0.3259601199824146, 0.31585584193501204, 0.35091247167728873]\n",
      "The mean squared error is  0.2324809305373551\n",
      "Final prediction given by the Neural Network is  [0.31547604482093417, 0.31352903188959746, 0.3532523880218561]\n",
      "The mean squared error is  0.2318515915191458\n",
      "Final prediction given by the Neural Network is  [0.4044426704403097, 0.34121472145613213, 0.346774062147588]\n",
      "The mean squared error is  0.1971227563696649\n",
      "Final prediction given by the Neural Network is  [0.32636278693768817, 0.31593763092469723, 0.3508132995764799]\n",
      "The mean squared error is  0.23250798821412919\n",
      "Final prediction given by the Neural Network is  [0.415961570287813, 0.346174979917676, 0.348046121962957]\n",
      "The mean squared error is  0.19402470237171135\n",
      "Final prediction given by the Neural Network is  [0.3924163048872981, 0.3380013383667066, 0.34822691160526675]\n",
      "The mean squared error is  0.20155494442354394\n",
      "Final prediction given by the Neural Network is  [0.2953999520488976, 0.30900757508883375, 0.3579168204733723]\n",
      "The mean squared error is  0.1983392075212653\n",
      "Final prediction given by the Neural Network is  [0.3109098409578111, 0.3125098181612041, 0.35429291777564326]\n",
      "The mean squared error is  0.23161038363837694\n",
      "Final prediction given by the Neural Network is  [0.3254504123227877, 0.31570911830517323, 0.3509747779083824]\n",
      "The mean squared error is  0.2089413190577253\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_y(i):\n",
    "    train_y = [0,0,0]\n",
    "    train_y[i] = 1\n",
    "    return train_y\n",
    "\n",
    "nn = NeuralNetwork(X_train[0],0.35,0.6,2,get_y(y_train[0]))\n",
    "\n",
    "prediction = []\n",
    "for j in range(10):\n",
    "    for i in range(1, len(X_train)):\n",
    "        nn.train(X_train[i], get_y(y_train[i]))\n",
    "    \n",
    "for i in range(1, len(X_test)):\n",
    "    output,e = nn.predict(X_test[i], get_y(y_test[i]))\n",
    "    print('Final prediction given by the Neural Network is ', output)\n",
    "    print('The mean squared error is ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = X.shape[1]\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "150/150 [==============================] - 0s 2ms/step - loss: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a24155f60>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Specify the model\n",
    "n_cols = X.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(32, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
