{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from Dotua.autodiff import AutoDiff as ad\n",
    "from Dotua.rautodiff import rAutoDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reverse Mode Implementation: High Level\n",
    "\n",
    "- Efficiency\n",
    "- Ease of Use\n",
    "- Expressibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Efficiency\n",
    "\n",
    "- Gradient computaional overhead scales linearly in the number of user defined functions\n",
    "- Favorable for certain applications in comparison to forward mode where overhead scales linearly in the number of input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ease of Use\n",
    "\n",
    "- Comparable to NumPy usage syntax\n",
    "- Limited initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dotua.nodes.rscalar.rScalar at 0x104b50780>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.sin(5)\n",
    "\n",
    "from Dotua.roperator import rOperator as rop\n",
    "from Dotua.rautodiff import rAutoDiff\n",
    "\n",
    "rop.sin(5)\n",
    "\n",
    "rad = rAutoDiff()\n",
    "x = rad.create_rscalar(5)\n",
    "rop.sin(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expressibility\n",
    "\n",
    "### Given that **Dotua** aims to be a partial NumPy replacement, it is essential that users can be as mathematically expressive with **Dotua** as the can be with NumPy.  \n",
    "\n",
    "__Operator Support__:\n",
    "- Basic functions: addition, subtraction, multiplication, division, exponentiation, and negation\n",
    "- Trigonometric functions: sine, cosine, and tangent\n",
    "- Inverse trigonometric functions: arcsine, arccosine, arctangent, \n",
    "- Hyperbolic functions and their inverses: sine, cosine, and tangents\n",
    "- Logarithms of any base\n",
    "- Natural exponentials\n",
    "\n",
    "__Functional Support__:\n",
    "- Roots of arbitrary degree\n",
    "- Logistic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.578175798120918"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.639349254446802"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-3.0650168320059885"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "-0.0007596792228180783"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.07206032210419326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3.519659904572385"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4.701912943875016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from Dotua.roperator import rOperator as rop\n",
    "\n",
    "# Complex function demo\n",
    "rad = rAutoDiff()\n",
    "\n",
    "vals = [0.5, 11, 13, 17, 23, 0.4]\n",
    "a, b, c, d, f, h = rad_initializer.create_rscalar(vals)\n",
    "\n",
    "# func = a + b\n",
    "\n",
    "func = rop.arccosh(b) / (rop.log(c) ** (rop.arcsin(b ** -2))) + \\\n",
    "       rop.cos((rop.tan(h + a) ** rop.log(d * h, base=2)) / (rop.sin(f) * rop.cos(f)))\n",
    "\n",
    "display(func.eval())\n",
    "display(rad_initializer.partial(func, a))\n",
    "display(rad_initializer.partial(func, b))\n",
    "display(rad_initializer.partial(func, c))\n",
    "display(rad_initializer.partial(func, d))\n",
    "display(rad_initializer.partial(func, f))\n",
    "display(rad_initializer.partial(func, h))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reverse Mode Implementation: Low Level\n",
    "\n",
    "- Constructing the computational graph\n",
    "- Calculating gradients\n",
    "- Handling multiple functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing the Computational Graph\n",
    "\n",
    "- The *parents* class variable of **rScalar** objects stores the computational graph and derivatives.  \n",
    "- Operator overloading and Dotua's elementary functions provide this support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing the Computational Graph: rScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def __init__(self, val):\n",
    "    self.val = val\n",
    "    self.parents = []\n",
    "    self.grad_val = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The *parents* member variable is a list of tuples of the form *(parent, value)*\n",
    "- *parent* is an **rScalar** created by operator overloading or elementary functions in **rOperator**\n",
    "- *value* is  d(parent) / d(self)\n",
    "- This storage method delays derivative computation until the user specifies the function to be differentiated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing the Computational Graph: rScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def __mul__(self, other):\n",
    "    new_parent = rScalar(self.val)\n",
    "    try:\n",
    "        new_parent.val *= other.val\n",
    "        self.parents.append((new_parent, other.val))\n",
    "        other.parents.append((new_parent, self.val))\n",
    "    except AttributeError:\n",
    "        new_parent.val *= other\n",
    "        self.parents.append((new_parent, other))\n",
    "    return new_parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **rScalar** overloaded operators create intermediary nodes in the computational graph\n",
    "- **rScalar** overloaded operators assign new nodes as the parents of the **rScalar** variables that define them\n",
    "- Dotua's **rOperator** functions can also handle non-rScalar objects (Python numeric types) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Constructing the Computational Graph: rOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def sin(x):\n",
    "    try:\n",
    "        new_parent = rScalar(np.sin(x.val))\n",
    "        x.parents.append((new_parent, np.cos(x.val)))\n",
    "        return new_parent\n",
    "\n",
    "    except AttributeError:\n",
    "        return np.sin(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **rOperator** functions also create intermediary nodes in the computational graph\n",
    "- **rOperator** functions also assign new nodes as the parents of the **rScalar** variables that define them\n",
    "- Dotua's **rOperator** functions can also handle non-rScalar objects (Python numeric types) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating Gradients\n",
    "\n",
    "- The **rAutoDiff** class provides a user interface for calculating derivatives of functions of **rScalar** and **rVector** variables\n",
    "- The **rScalar** and **rVector** gradient methods use the computational graph representations stored in **rScalar** and **rVector** objects to determine derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Calculating Gradients: rScalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def gradient(self):\n",
    "    if self.grad_val is None:\n",
    "        self.grad_val = 0\n",
    "        for parent, val in self.parents:\n",
    "            self.grad_val += parent.gradient() * val\n",
    "    return self.grad_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **rScalar** variables recursively use the computational graph defined in *self.parents*\n",
    "- The derivative computation bubbles up to the level of user defined functions \n",
    "- Derivatives are propagated back down to the user defined input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Functions\n",
    "\n",
    "- Initialize and manage **rScalar** objects through a centralized object: **rAutoDiff**\n",
    "- **rAutoDiff** objects provide user interface for calculating derivatives\n",
    "- **rAutoDiff** objects \"know\" when to reset **rScalar** gradient class variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Multiple Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def __init__(self):\n",
    "    self._func = None\n",
    "    self._universe = []\n",
    "\n",
    "def _reset_universe(self, var):\n",
    "    var.grad_val = None\n",
    "    for parent, _ in var.parents:\n",
    "        self._reset_universe(parent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **rAutoDiff** objects keep track of user defined **rScalar** objects\n",
    "- **rAutoDiff** \"remember\" the last function the user differentiated\n",
    "- When necessary, **rAutoDiff** objects can reset the gradient values cached in all **rScalar** variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def partial(self, func, var):\n",
    "    if (self._func != func):\n",
    "        for item in self._universe:\n",
    "            self._reset_universe(item)\n",
    "        func.grad_val = 1\n",
    "        self._func = func\n",
    "    return var.gradient()\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
